{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/labs/mini_lab\n"
     ]
    }
   ],
   "source": [
    "# ms-python.python added\n",
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), 'labs/mini_lab'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add library references\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import plotly.plotly as py\n",
    "#import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education_num',\n",
    "    'marital_status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'gender',\n",
    "    'capital_gain',\n",
    "    'capital_loss',\n",
    "    'hours_per_week',\n",
    "    'native_country',\n",
    "    'income_bracket'\n",
    "]\n",
    "cat_cols = [\n",
    "    \"workclass\",\n",
    "    \"marital_status\", \n",
    "    \"occupation\",\n",
    "    \"race\", \n",
    "    \"gender\",\n",
    "    \"relationship\"]\n",
    "\n",
    "cont_cols = [\n",
    "    \"age\", \n",
    "    \"education_num\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\"]\n",
    "\n",
    "drop_cols = [\n",
    "    'fnlwgt',\n",
    "    \"native_country\",\n",
    "    \"education\"]\n",
    "\n",
    "target_col = \"target\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv(\"data/adult-training.csv\",\n",
    "    names=df_cols, \n",
    "    skipinitialspace = True)\n",
    "\n",
    "df_test = pd.read_csv(\"data/adult-test.csv\",\n",
    "    names = df_cols,\n",
    "    skipinitialspace = True,\n",
    "    skiprows=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[target_col] = (df_training[\"income_bracket\"]\n",
    "    .apply(lambda x: \">50K\" in x)).astype(int)\n",
    "df_test[target_col] = (df_test[\"income_bracket\"]\n",
    "    .apply(lambda x: \">50K\" in x)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT LOUD NOISES FOR ONE AND ALL. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all education values that didnt graduate HS 'No Diploma'\n",
    "# the 2 associate values to Associates\n",
    "# some college and HS-grad to Diploma\n",
    "replace_edu_no = ('1st-4th', '5th-6th','7th-8th','9th', '10th', '11th', '12th', 'Preschool')\n",
    "replace_edu_associate = ('Assoc-acdm', 'Assoc-voc')\n",
    "replace_edu_diploma = ('Some-college', 'HS-grad')\n",
    "\n",
    "df_training.education = df_training.education.replace(to_replace=replace_edu_no,value='No Diploma')\n",
    "df_training.education = df_training.education.replace(to_replace=replace_edu_associate,value='Associates')\n",
    "df_training.education = df_training.education.replace(to_replace=replace_edu_diploma,value='Diploma')\n",
    "\n",
    "df_test.education = df_test.education.replace(to_replace=replace_edu_no,value='No Diploma')\n",
    "df_test.education = df_test.education.replace(to_replace=replace_edu_associate,value='Associates')\n",
    "df_test.education = df_test.education.replace(to_replace=replace_edu_diploma,value='Diploma')\n",
    "\n",
    "df_training['education'] = df_training['education'].str.strip()\n",
    "df_test['education'] = df_test['education'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put countries in their native region continent\n",
    "replace_northA = ('United-States', 'Honduras', 'Mexico','Puerto-Rico','Canada', 'Outlying-US(Guam-USVI-etc)', 'Nicaragua', 'Guatemala', 'El-Salvador')\n",
    "replace_carib = ('Cuba', 'Jamaica', 'Trinadad&Tobago', 'Haiti', 'Dominican-Republic')\n",
    "replace_asia = ('South', 'Cambodia','Thailand','Laos', 'Taiwan', 'China', 'Japan', 'India', 'Iran', 'Philippines', 'Vietnam', 'Hong')\n",
    "replace_europe = ('England', 'Germany', 'Portugal', 'Italy', 'Poland', 'France', 'Yugoslavia','Scotland', 'Greece', 'Ireland', 'Hungary', 'Holand-Netherlands')\n",
    "replace_sa = ('Columbia', 'Ecuador', 'Peru')\n",
    "replace_other = ('?')\n",
    "df_training.native_country = df_training.native_country.replace(to_replace=replace_northA,value='North America')\n",
    "df_training.native_country = df_training.native_country.replace(to_replace=replace_carib,value='Caribbean')\n",
    "df_training.native_country = df_training.native_country.replace(to_replace=replace_asia,value='Asia')\n",
    "df_training.native_country = df_training.native_country.replace(to_replace=replace_europe,value='Europe') \n",
    "df_training.native_country = df_training.native_country.replace(to_replace=replace_sa,value='South America')\n",
    "df_training.native_country = df_training.native_country.replace(to_replace=replace_other,value='Other')   \n",
    "\n",
    "df_test.native_country = df_test.native_country.replace(to_replace=replace_northA,value='North America')\n",
    "df_test.native_country = df_test.native_country.replace(to_replace=replace_carib,value='Caribbean')\n",
    "df_test.native_country = df_test.native_country.replace(to_replace=replace_asia,value='Asia')\n",
    "df_test.native_country = df_test.native_country.replace(to_replace=replace_europe,value='Europe') \n",
    "df_test.native_country = df_test.native_country.replace(to_replace=replace_sa,value='South America')\n",
    "df_test.native_country = df_test.native_country.replace(to_replace=replace_other,value='Other') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_training.drop(drop_cols,axis=1,inplace=True)\n",
    "df_test.drop(drop_cols,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training2 = df_training.copy()\n",
    "df_test2 = df_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dummy(df,cols):\n",
    "    dummies = []\n",
    "    for cat in cols:\n",
    "        dummy = pd.get_dummies(df[cat],\n",
    "        drop_first=True)\n",
    "        dummies.append(dummy)\n",
    "        df.drop(cat,axis=1,inplace=True)\n",
    "    \n",
    "    return pd.concat([df,*dummies], axis=1)\n",
    "\n",
    "df_training_dum = convert_dummy(df_training.copy(),cat_cols)\n",
    "df_test_dum = convert_dummy(df_test.copy(),cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_training_dum.drop(columns=[\"income_bracket\",target_col])\n",
    "y_train = df_training_dum[target_col]\n",
    "X_test = df_test_dum.drop(columns=[\"income_bracket\",target_col])\n",
    "y_test = df_test_dum[target_col]\n",
    "\n",
    "X_train2 = df_training2.drop(columns=[\"income_bracket\",target_col])\n",
    "y_train2 = df_training2[target_col]\n",
    "X_test2 = df_test2.drop(columns=[\"income_bracket\",target_col])\n",
    "y_test2 = df_test2[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score , classification_report, log_loss\n",
    "from sklearn.svm import LinearSVC, SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py:751: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "preprocess = make_column_transformer(\n",
    "    (cont_cols ,make_pipeline(SimpleImputer(), StandardScaler())),\n",
    "    (cat_cols, OneHotEncoder()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression(solver='liblinear')\n",
    "model2 = make_pipeline(\n",
    "    preprocess,\n",
    "    LogisticRegression(solver='liblinear'))\n",
    "\n",
    "svm1 = LinearSVC(C=0.007)\n",
    "svm1.fit(X_train, y_train)\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train2,y_train2)\n",
    "\n",
    "predictions1 = model1.predict(X_test)\n",
    "predictions2 = model2.predict(X_test2)\n",
    "\n",
    "svm_predictions = svm1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     12435\n",
      "           1       0.73      0.60      0.66      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.81      0.76      0.78     16281\n",
      "weighted avg       0.85      0.85      0.85     16281\n",
      "\n",
      "Accuracy: 0.8530188563356059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     12435\n",
      "           1       0.73      0.60      0.66      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.81      0.77      0.78     16281\n",
      "weighted avg       0.85      0.85      0.85     16281\n",
      "\n",
      "Accuracy: 0.8524660647380382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     12435\n",
      "           1       0.71      0.39      0.50      3846\n",
      "\n",
      "    accuracy                           0.82     16281\n",
      "   macro avg       0.77      0.67      0.70     16281\n",
      "weighted avg       0.80      0.82      0.80     16281\n",
      "\n",
      "Accuracy: 0.8177016153798907\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions1))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, predictions1))\n",
    "\n",
    "print(classification_report(y_test2,predictions2))\n",
    "print(\"Accuracy:\",accuracy_score(y_test2, predictions2))\n",
    "\n",
    "print(classification_report(y_test,svm_predictions))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, svm_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     12435\n",
      "           1       0.73      0.60      0.66      3846\n",
      "\n",
      "    accuracy                           0.85     16281\n",
      "   macro avg       0.81      0.76      0.78     16281\n",
      "weighted avg       0.85      0.85      0.85     16281\n",
      "\n",
      "\n",
      "Accuracy:    0.853019\n",
      "\n",
      "Log Loss:    5.076590\n",
      "\n",
      "Continuous Columns:\n",
      "['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "\n",
      "Categorical Columns:\n",
      "['workclass', 'marital_status', 'occupation', 'race', 'gender', 'relationship']\n",
      "\n",
      "Drop Columns:\n",
      "['fnlwgt', 'native_country', 'education']\n",
      "\n",
      "================================================================================"
     ]
    }
   ],
   "source": [
    "\n",
    "logLoss = log_loss(y_test,predictions1)\n",
    "print(\n",
    "    \"=\"*80,\n",
    "    classification_report(y_test,predictions1),\n",
    "    \"Accuracy:    %f\" %accuracy_score(y_test, predictions1),\n",
    "    \"Log Loss:    %f\" % logLoss,\n",
    "    \"Continuous Columns:\\n%a\" % cont_cols,\n",
    "    \"Categorical Columns:\\n%a\" %cat_cols,\n",
    "    \"Drop Columns:\\n%a\" %drop_cols,\n",
    "    sep=\"\\n\\n\",\n",
    "    end=\"\\n\\n\"+(\"=\"*80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
